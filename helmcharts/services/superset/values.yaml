namespace: superset
# global:
global:
  postgresql:
    user: "postgres"
    password: "postgres"
    host: "postgresql-hl.postgresql.svc.cluster.local"
    port: 5432
  redis_dedup:
    host: redis-dedup.redis.svc.cluster.local
    port: 6379

postgresql:
  db_name: "superset"
  db_username: "superset"
  db_password: "superset123"
redis:
  db_index: 3

replicaCount: 1
oauth_enabled: true

adminUser:
  username: "admin"
  firstname: "Superset"
  lastname: "Admin"
  email: "admin@superset.com"
  password: "admin123"

oauth:
  enabled: true
  client_id: ""
  client_secret: ""
  auth_token: ""
  email_whitelist_regex: ""
  whitelist_domain: ""
  user_registration_role: "Gamma"

runAsUser: 1000

# Install additional packages and do any other bootstrap configuration in this script
# For production clusters it's recommended to build own image with this step done in CI
bootstrapScript: |
  #!/bin/bash
  #rm -rf /var/lib/apt/lists/* && \
  pip install \
    redis==3.2.1 && \
  if [ ! -f ~/bootstrap ]; then echo "Running Superset with uid {{ .Values.runAsUser }}" > ~/bootstrap; fi

## The name of the secret which we will use to generate a superset_config.py file
## Note: this secret must have the key superset_config.py in it and can include other files as well
##
configFromSecret: '{{ template "superset.fullname" . }}-config'

## The name of the secret which we will use to populate env vars in deployed pods
## This can be useful for secret keys, etc.
##
envFromSecret: '{{ template "superset.fullname" . }}-env'
## This can be a list of template strings
envFromSecrets: []

## Extra environment variables that will be passed into pods
##
extraEnv: {}
  # Extend timeout to allow long running queries.
  # GUNICORN_TIMEOUT: 300


   # OAUTH_HOME_DOMAIN: ..
  # # If a whitelist is not set, any address that can use your OAuth2 endpoint will be able to login.
  # #   this includes any random Gmail address if your OAuth2 Web App is set to External.
  # OAUTH_WHITELIST_REGEX: ...

## Extra environment variables to pass as secrets
##
extraSecretEnv: {}
  # MAPBOX_API_KEY: ...
  # # Google API Keys: https://console.cloud.google.com/apis/credentials
  # GOOGLE_KEY: ...
  # GOOGLE_SECRET: ...

extraConfigs: {}
  # datasources-init.yaml: |
  #     databases:
  #     - allow_csv_upload: true
  #       allow_ctas: true
  #       allow_cvas: true
  #       database_name: example-db
  #       extra: "{\r\n    \"metadata_params\": {},\r\n    \"engine_params\": {},\r\n    \"\
  #         metadata_cache_timeout\": {},\r\n    \"schemas_allowed_for_csv_upload\": []\r\n\
  #         }"
  #       sqlalchemy_uri: example://example-db.local
  #       tables: []

extraSecrets:
  custom_sso_security_manager.py: |
    import logging
    import json
    from superset.security import SupersetSecurityManager

    class CustomSsoSecurityManager(SupersetSecurityManager):

      def oauth_user_info(self, provider, response=None):
        print("Oauth2 provider:", provider)
        if provider == 'obsrv':
          # As example, this line request a GET to base_url + '/' + userDetails with Bearer  Authentication,
          # and expects that authorization server checks the token, and response with user details
          response = self.appbuilder.sm.oauth_remotes[provider].get('console/api/oauth/v1/userinfo').__dict__
          content = response['_content'].decode('utf-8')
          data = json.loads(content)
          print("Oauth2 User Data:", data)
          id = data['id']
          name = data['name']
          email = data['email']
          return { 'name' :name, 'email' : email, 'id' : id, 'username' : name, 'first_name':'', 'last_name':''}

# A dictionary of overrides to append at the end of superset_config.py - the name does not matter
# WARNING: the order is not guaranteed
configOverrides:
  enable_feature_flags: |
    FEATURE_FLAGS = {
      "DASHBOARD_NATIVE_FILTERS": True,
      "DASHBOARD_CROSS_FILTERS": True,
      "DASHBOARD_NATIVE_FILTERS_SET": True,
      "ENABLE_TEMPLATE_PROCESSING": True,
    }

  data_cache_config: |
    DATA_CACHE_CONFIG = {
      'CACHE_TYPE': 'redis',
      'CACHE_DEFAULT_TIMEOUT': 600,
      'CACHE_KEY_PREFIX': 'superset_',
      'CACHE_REDIS_URL': 'redis://{{ tpl .Values.global.redis_dedup.host . }}:{{ tpl (.Values.global.redis_dedup.port | toString) . }}/{{ tpl (toString .Values.redis.db_index) $ }}'
    }

  sql_alchemy_config: |
    SQLALCHEMY_DATABASE_URI = 'postgresql://{{ tpl .Values.postgresql.db_username . }}:{{ tpl .Values.postgresql.db_password . }}@{{ tpl .Values.global.postgresql.host . }}:{{ tpl (.Values.global.postgresql.port | toString) . }}/{{ tpl .Values.postgresql.db_name . }}'
    SQLALCHEMY_TRACK_MODIFICATIONS = True
    SECRET_KEY = 'thisISaSECRET_1234'

  # map_box_key: |
  #  MAPBOX_API_KEY=''

  oauth: |
    from flask_appbuilder.security.manager import AUTH_OAUTH

    AUTH_TYPE = AUTH_OAUTH

    OAUTH_PROVIDERS = [
      {
        'name':'obsrv',
        'token_key':'access_token',
        'icon':'fa-address-card',
        'remote_app': {
           'client_id':'{{ .Values.oauth.client_id }}',
           'client_secret':'{{ .Values.oauth.client_secret }}',
           'client_kwargs':{
               'scope': 'read'
           },
           'access_token_method':'POST',
           'access_token_params':{
               'client_id':'{{ .Values.oauth.client_id }}',
               'client_secret':'{{ .Values.oauth.client_secret }}'
           },
           'access_token_headers':{
               'Authorization': 'Basic {{ .Values.oauth.auth_token }}'
           },
           'api_base_url':'https://{{ .Values.global.domain }}',
           'access_token_url':'https://{{ .Values.global.domain }}/console/api/oauth/v1/token',
           'authorize_url':'/console/api/oauth/v1/authorize'
        }
      }
    ]
    AUTH_USER_REGISTRATION = True
    AUTH_OAUTH_REDIRECT_URI='https://{{ .Values.global.domain }}/oauth-authorized/obsrv'
    AUTH_USER_REGISTRATION_ROLE = "Admin"
    ENABLE_PROXY_FIX = True

    from custom_sso_security_manager import CustomSsoSecurityManager
    CUSTOM_SECURITY_MANAGER = CustomSsoSecurityManager

configMountPath: "/app/pythonpath"
extraConfigMountPath: "/app/configs"
dashboardMountPath: "/app/dashboards"

image: &image
  registry: docker.io
  repository: apache/superset
  tag: 3.0.2
  pullPolicy: IfNotPresent

<<: *image

imagePullSecrets: []

service:
  type: ClusterIP
  port: 8088
  annotations: {}

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    ## Extend timeout to allow long running queries.
    # nginx.ingress.kubernetes.io/proxy-connect-timeout: "300"
    # nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    # nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  path: /
  pathType: ImplementationSpecific
  hosts:
    - chart-example.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 512m
    memory: 1024Mi
  requests:
    cpu: 250m
    memory: 512Mi

##
## Superset node configuration
supersetNode:
  connections:
    redis_host: "{{ .Values.global.redis_dedup.host }}"
    redis_port: "{{ .Values.global.redis_dedup.port }}"
    db_host: "{{ .Values.global.postgresql.host }}"
    db_port: "{{ .Values.global.postgresql.port }}"
    db_user: "{{ .Values.postgresql.db_username }}"
    db_pass: "{{ .Values.postgresql.db_password }}"
    db_name: "{{ .Values.postgresql.db_name }}"
  forceReload: false # If true, forces deployment to reload on each upgrade
  # initContainers:
  #   - name: wait-for-postgres
  #     image: busybox:latest
  #     imagePullPolicy: IfNotPresent
  #     envFrom:
  #       - secretRef:
  #           name: '{{ tpl .Values.envFromSecret . }}'
  #     command: [ "/bin/sh", "-c", "until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done" ]
  ## Annotations to be added to supersetNode deployment
  deploymentAnnotations: {}
  ## Annotations to be added to supersetNode pods
  podAnnotations: {}

##
## Init job configuration
init:
  # Configure resources
  # Warning: fab command consumes a lot of ram and can
  # cause the process to be killed due to OOM if it exceeds limit
  resources: {}
    # limits:
    #   cpu:
    #   memory:
    # requests:
    #   cpu:
    #   memory:
  command:
    - "/bin/sh"
    - "-c"
    - ". {{ .Values.configMountPath }}/superset_bootstrap.sh; . {{ .Values.configMountPath }}/superset_init.sh"
  enabled: true
  createAdmin: true
  # initContainers:
  #   - name: wait-for-postgres
  #     image: busybox:latest
  #     imagePullPolicy: IfNotPresent
  #     envFrom:
  #       - secretRef:
  #           name: '{{ tpl .Values.envFromSecret . }}'
  #     command: [ "/bin/sh", "-c", "until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done" ]
  initscript: |-
    #!/bin/sh
    echo "Upgrading DB schema..."
    superset db upgrade
    echo "Initializing roles..."
    superset init
    {{ if .Values.init.createAdmin }}
    echo "Creating admin user..."
    superset fab create-admin \
                    --username {{ .Values.adminUser.username }} \
                    --firstname {{ .Values.adminUser.firstname }} \
                    --lastname {{ .Values.adminUser.lastname }} \
                    --email {{ .Values.adminUser.email }} \
                    --password {{ .Values.adminUser.password }} \
                    || true
    {{ end }}
    if [ -f "{{ .Values.extraConfigMountPath }}/import_datasources.yaml" ]; then
      echo "Importing database connections.... "
      superset import_datasources -p {{ .Values.extraConfigMountPath }}/import_datasources.yaml
    fi

    if [ -f "{{ .Values.dashboardMountPath }}/dashboards.zip" ]; then
      echo "Importing dashboards.... "
      superset import-dashboards --path "{{ .Values.dashboardMountPath }}/dashboards.zip"
    else
      echo "File /app/dashboards/dashboards.zip not found..."
    fi

nodeSelector: {}

tolerations: []

affinity: {}
