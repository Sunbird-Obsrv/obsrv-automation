namespace: "pyflink"
imagepullsecrets: ""
image:
  registry: ""
  repository: sanketikahub/flink-python
  tag: 1.0.0
serviceMonitor:
  enabled: false
replicaCount: 1

jobmanager:
  rpc_port: 6123
  blob_port: 6124
  query_port: 6125
  ui_port: 8081
  prom_port: 9250
  heap_memory: 1024
  cpu_requests: 0.25
  cpu_limits: 0.25
  memory_requests: 1024Mi
  memory_limits: 1024Mi

rest_port: 80
resttcp_port: 8081
service:
  type: ClusterIP

taskmanager:
  prom_port: 9251
  rpc_port: 6122
  heap_memory: 1024
  replicas: 1
  cpu_requests: 0.5
  cpu_limits: 0.5
  memory_requests: 1024Mi
  memory_limits: 1024Mi

pyjobmanager:
  port: 5000
  cpu_requests: 0.1
  cpu_limits: 0.1
  memory_requests: 512Mi
  memory_limits: 512Mi


checkpoint_store_type: "s3"

# AWS S3 Details
s3_access_key: ""
s3_secret_key: ""
s3_endpoint: ""

# Azure Container Details
azure_account: ""
azure_secret: ""

# Google Cloud Storage Service Account JSON Path
google_service_account_key_path: ""

log4j_console_properties: |
  # This affects logging for both user code and Flink
  rootLogger.level = INFO
  rootLogger.appenderRef.console.ref = ConsoleAppender

  # Uncomment this if you want to _only_ change Flink's logging
  logger.flink.name = org.apache.flink
  logger.flink.level = INFO

  # The following lines keep the log level of common libraries/connectors on
  # log level INFO. The root logger does not override this. You have to manually
  # change the log levels here.
  logger.akka.name = akka
  logger.akka.level = ERROR
  logger.kafka.name= org.apache.kafka
  logger.kafka.level = ERROR
  logger.hadoop.name = org.apache.hadoop
  logger.hadoop.level = ERROR
  logger.zookeeper.name = org.apache.zookeeper
  logger.zookeeper.level = ERROR

  # Log all infos to the console
  appender.console.name = ConsoleAppender
  appender.console.type = CONSOLE
  appender.console.layout.type = PatternLayout
  appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

  # Suppress the irrelevant (wrong) warnings from the Netty channel handler
  logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
  logger.netty.level = OFF

jobmanager-flink-conf: |+
  jobmanager.memory.flink.size: 1024m
  taskmanager.memory.flink.size: 1024m
  taskmanager.numberOfTaskSlots: 1
  jobManager.numberOfTaskSlots: 1
  parallelism.default: 1
  jobmanager.execution.failover-strategy: region
  taskmanager.memory.network.fraction: 0.1
  scheduler-mode: reactive
  heartbeat.timeout: 8000
  heartbeat.interval: 5000
  taskmanager.memory.process.size: 1700m
  jobmanager.memory.process.size: 1600m
  state.savepoints.dir: file:///tmp

unified-pipeline:
  unified-pipeline: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".ingest"
      output.raw.topic = ${job.env}".raw"
      output.extractor.duplicate.topic = ${job.env}".extractor.duplicate"
      output.failed.topic = ${job.env}".failed"
      output.batch.failed.topic = ${job.env}".extractor.failed"
      event.max.size = "1048576" # Max is only 1MB
      output.invalid.topic = ${job.env}".invalid"
      output.unique.topic = ${job.env}".unique"
      output.duplicate.topic = ${job.env}".duplicate"
      output.denorm.topic = ${job.env}".denorm"
      output.denorm.failed.topic = ${job.env}".denorm.failed"
      output.transform.topic = ${job.env}".transform"
      output.transform.failed.topic = ${job.env}".failed"
      stats.topic = ${job.env}".stats"
      groupId = ${job.env}"-single-pipeline-group"
      producer {
        max-request-size = 5242880
      }
    }
    task {
      window.time.in.seconds = 5
      window.count = 30
      window.shards = 1400
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

    redis {
      database {
        extractor.duplication.store.id = 1
        preprocessor.duplication.store.id = 2
        key.expiry.seconds = 3600
      }
    }
  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    taskmanager.memory.process.size: 1700m
    jobmanager.memory.process.size: 1600m
    state.savepoints.dir: file:///tmp
  job_classname: org.sunbird.obsrv.pipeline.task.UnifiedPipelineStreamTask

extractor:
  extractor: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".ingest"
      output.raw.topic = ${job.env}".raw"
      output.extractor.duplicate.topic = ${job.env}".extractor.duplicate"
      output.failed.topic = ${job.env}".failed"
      output.batch.failed.topic = ${job.env}".extractor.failed"
      event.max.size = "1048576" # Max is only 1MB
      groupId = ${job.env}"-extractor-group"
      producer {
        max-request-size = 5242880
      }
    }

    task {
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

    redis {
      database {
        extractor.duplication.store.id = 1
        key.expiry.seconds = 3600
      }
    }

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.extractor.task.ExtractorStreamTask

preprocessor:
  preprocessor: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".raw"
      output.failed.topic = ${job.env}".failed"
      output.invalid.topic = ${job.env}".invalid"
      output.unique.topic = ${job.env}".unique"
      output.duplicate.topic = ${job.env}".duplicate"
      groupId = ${job.env}"-pipeline-preprocessor-group"
    }

    task {
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

    redis {
      database {
        preprocessor.duplication.store.id = 2
        key.expiry.seconds = 3600
      }
    }

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.preprocessor.task.PipelinePreprocessorStreamTask

denormalizer:
  denormalizer: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".unique"
      output.denorm.topic = ${job.env}".denorm"
      output.denorm.failed.topic = ${job.env}".denorm.failed"
      groupId = ${job.env}"-denormalizer-group"
    }

    task {
      window.time.in.seconds = 5
      window.count = 30
      window.shards = 1400
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.denormalizer.task.DenormalizerWindowStreamTask

transformer:
  transformer: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".denorm"
      output.transform.topic = ${job.env}".transform"
      output.transform.failed.topic = ${job.env}".failed"
      groupId = ${job.env}"-transformer-group"
      producer {
        max-request-size = 5242880
      }
    }

    task {
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.transformer.task.TransformerStreamTask

druid-router:
  druid-router: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".transform"
      stats.topic = ${job.env}".stats"
      groupId = ${job.env}"-druid-router-group"
    }

    task {
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.router.task.DruidRouterStreamTask


kafka-connector:
  kafka-connector: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".test"
      output.topic = ${job.env}".ingest"  # output and input topics will be fetched from postgres records
      output.failed.topic = ${job.env}".failed"
      event.max.size = "1048576" # Max is only 1MB
      groupId = ${job.env}"-kafkaconnector-group"
      producer {
        max-request-size = 5242880
      }
    }

    task {
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }
  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.kafkaconnector.task.KafkaConnectorStreamTask

master-data-processor:
  master-data-processor: |+
    include file("/data/flink/conf/baseconfig.conf")
    kafka {
      input.topic = ${job.env}".masterdata.ingest"
      output.raw.topic = ${job.env}".masterdata.raw"
      output.extractor.duplicate.topic = ${job.env}".masterdata.extractor.duplicate"
      output.failed.topic = ${job.env}".masterdata.failed"
      output.batch.failed.topic = ${job.env}".masterdata.extractor.failed"
      event.max.size = "1048576" # Max is only 1MB
      output.invalid.topic = ${job.env}".masterdata.invalid"
      output.unique.topic = ${job.env}".masterdata.unique"
      output.duplicate.topic = ${job.env}".masterdata.duplicate"
      output.transform.topic = ${job.env}".masterdata.transform"
      output.transform.failed.topic = ${job.env}".failed"
      stats.topic = ${job.env}".masterdata.stats"
      groupId = ${job.env}"-masterdata-pipeline-group"

      producer {
        max-request-size = 5242880
      }
    }

    task {
      window.time.in.seconds = 5
      window.count = 30
      window.shards = 1400
      consumer.parallelism = 1
      downstream.operators.parallelism = 1
    }

    redis {
      database {
        extractor.duplication.store.id = 1
        preprocessor.duplication.store.id = 2
        key.expiry.seconds = 3600
      }
    }

    dataset.type = "master-dataset"

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    state.savepoints.dir: file:///tmp

  job_classname: org.sunbird.obsrv.pipeline.task.MasterDataProcessorStreamTask

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""